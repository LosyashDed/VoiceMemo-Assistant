"""
Voice Telegram Bot
===================
A modular Telegram bot that transcribes incoming voice messages, summarizes them with an
LLM (local or cloud), and stores both the raw transcription and the summary in a database.

Architecture Overview
---------------------
â€¢ ``Database`` â€“ Thin wrapper around SQLite **(switchable to MySQL later)**
â€¢ ``LLMHandler`` â€“ Talks to either a **local** Ollama instance *or* a cloud LLM (e.g. OpenAI)
â€¢ ``SpeechToText`` â€“ Converts OGG âœ WAV (via FFmpeg) and transcribes with **Vosk**
â€¢ ``TelegramBot`` â€“ Handles the Telegram Bot API (using ``pythonâ€‘telegramâ€‘bot`` library)
â€¢ ``Utils`` â€“ Misc. helper utilities (static methods only)

Environment variables are read from a ``.env`` file â€“ **change behaviour by editing the file, not the code**.

Example .env
-------------
```
# â”€â”€â”€ Telegram â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TG_BOT_TOKEN="123456:ABCâ€‘DEFâ€¦â€

# â”€â”€â”€ Database â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DB_PATH="bot.db"              # Path to SQLite file (ignored if you later switch to MySQL)

# â”€â”€â”€ LLM Settings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
USE_LOCAL_LLM="True"          # "True" -> Ollama, "False" -> use cloud LLM
OLLAMA_BASE_URL="http://127.0.0.1:11434"  # Where your Ollama server sits
OLLAMA_MODEL="mistral"

OPENAI_API_KEY="skâ€‘â€¦"         # Only required when USE_LOCAL_LLM=False
OPENAI_MODEL="gptâ€‘3.5â€‘turbo"  # or gptâ€‘4o, etc.

# â”€â”€â”€ Speechâ€‘toâ€‘Text â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
VOSK_MODEL_PATH="models/voskâ€‘smallâ€‘ruâ€‘0.22"

# â”€â”€â”€ Misc â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LOG_FILE="bot.log"             # Where to write debug logs

```

Install dependencies
--------------------
```bash
python -m venv .venv && source .venv/bin/activate
pip install pythonâ€‘telegramâ€‘bot==20.8 pythonâ€‘dotenv requests vosk ffmpegâ€‘python openai
```
(Use ``pip install mysqlâ€‘connectorâ€‘python`` later if/when you migrate the DB.)

Run the bot
-----------
```bash
python voice_telegram_bot.py
```

-------------------------------------------------------------------------------
Below is the **fullyâ€‘commented** implementation. Feel free to slice it into
multiple files once you're comfortable â€“ the class boundaries are already set up
for easy extraction.
-------------------------------------------------------------------------------
"""
from __future__ import annotations

import datetime
import os
import sqlite3
import logging
import datetime as _dt
import json

import resampy
import soundfile as sf
import tempfile
from dataclasses import dataclass
from pathlib import Path
from typing import Optional, Dict, Any

import requests
from dotenv import load_dotenv
from vosk import Model, KaldiRecognizer
from telegram import Update, Voice, constants
from telegram.ext import ApplicationBuilder, ContextTypes, MessageHandler, filters
from telegram.ext import CommandHandler

try:
    import openai  # optional â€“ only needed when USE_LOCAL_LLM == False
except ImportError:
    openai = None  # keep linting happy â€“ runtime guard is in LLMHandler

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Utils
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class Utils:
    """Collection of helper static methods."""

    @staticmethod
    def now_utc() -> str:
        """Return current UTC time in ISOâ€‘8601 format (without microseconds)."""
        return datetime.datetime.now().replace(microsecond=0).isoformat()

    @staticmethod
    def ensure_parent(path: Path):
        path.parent.mkdir(parents=True, exist_ok=True)

    @staticmethod
    def as_bool(value: str | bool | None) -> bool:
        if isinstance(value, bool):
            return value
        return str(value).strip().lower() in {"1", "true", "yes", "on"}

    @staticmethod
    def configure_logging(log_path: str):
        fmt = "%(asctime)s | %(levelname)s | %(name)s | %(message)s"
        logging.basicConfig(
            level=logging.INFO,
            format=fmt,
            handlers=[
                logging.FileHandler(log_path, encoding="utfâ€‘8"),
                logging.StreamHandler(),
            ],
        )
        logging.getLogger("httpx").setLevel(logging.WARNING)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Database Layer
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class Database:
    """Lightweight wrapper around SQLite â€“ swappable later for MySQL.

    Only *this* class knows specific SQL dialect details. The rest of the code
    interacts through the typed public interface below. To migrate, rewrite
    these methods and keep signatures intact.
    """

    _CREATE_TABLE_SQL = """
    CREATE TABLE IF NOT EXISTS voice_messages (
        id          INTEGER PRIMARY KEY AUTOINCREMENT,
        telegram_file_id TEXT UNIQUE NOT NULL,
        text        TEXT,
        summarized  TEXT,
        sent_at     TEXT,
        user_id     INTEGER,
        username    TEXT
    );"""

    def __init__(self, path: str):
        Utils.ensure_parent(Path(path))
        self.conn = sqlite3.connect(path, check_same_thread=False)
        self.conn.execute("PRAGMA journal_mode=WAL;")  # better concurrency
        self.conn.execute("PRAGMA busy_timeout = 10000;")
        self.conn.execute(self._CREATE_TABLE_SQL)
        self.conn.commit()
        logging.info("Connected to SQLite DB at %s", path)

    def save_message(
        self,
        telegram_file_id: str,
        text: str | None,
        summary: str | None,
        sent_at: str,
        user_id: int,
        username: str | None,
    ) -> None:
        """Insert or update a transcription row."""
        self.conn.execute(
            """
            INSERT INTO voice_messages
                (telegram_file_id, text, summarized, sent_at, user_id, username)
            VALUES (?, ?, ?, ?, ?, ?)
            ON CONFLICT(telegram_file_id) DO UPDATE SET
                text=excluded.text,
                summarized=excluded.summarized,
                sent_at=excluded.sent_at;
            """,
            (telegram_file_id, text, summary, sent_at, user_id, username),
        )
        self.conn.commit()
        logging.debug("Saved message %s", telegram_file_id)

    # Example of an accessor you might need later.
    def fetch_last_n(self, n: int = 10):
        cur = self.conn.execute(
            "SELECT * FROM voice_messages ORDER BY id DESC LIMIT ?", (n,)
        )
        return cur.fetchall()

    def fetch_summaries_by_date(self, date_str: str) -> list[tuple[str, str, str]]:
        """
        Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ ÑĞ¿Ğ¸ÑĞ¾Ğº ĞºĞ¾Ñ€Ñ‚ĞµĞ¶ĞµĞ¹ (sent_at, username, summarized)
        Ğ´Ğ»Ñ Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹, Ñƒ ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… sent_at Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ĞµÑ‚ÑÑ Ñ date_str (YYYY-MM-DD).
        """
        cur = self.conn.execute(
            """
            SELECT sent_at, telegram_file_id, summarized
              FROM voice_messages
             WHERE sent_at LIKE ?
          ORDER BY sent_at ASC
            """,
            (f"{date_str}%",)
        )
        return cur.fetchall()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  LLM Handler
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class LLMHandler:
    """Facade that hides whether we call a *local* Ollama model or a *cloud* LLM."""

    def __init__(self, *, use_local: bool, cfg: Dict[str, str]):
        self.use_local = use_local
        self.cfg = cfg
        if not use_local and openai is None:
            raise RuntimeError(
                "OpenAI Python package is not installed but USE_LOCAL_LLM=False." )
        if not use_local:
            openai.api_key = cfg["OPENAI_API_KEY"]

    def summarize(self, text: str) -> str:
        """
        Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ñ€ĞµĞ·ÑĞ¼Ğµ Ñ ÑƒÑ‡Ñ‘Ñ‚Ğ¾Ğ¼ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ğ¸Ğ½Ñ‹.
        Ğ•ÑĞ»Ğ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ¾Ñ‚ĞºĞ»Ğ¾Ğ½ÑĞµÑ‚ÑÑ Ğ¾Ñ‚ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ğ° >20 %, Ğ´ĞµĞ»Ğ°ĞµĞ¼
        Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½ÑƒÑ Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚ĞºÑƒ â€” Ñ‡Ğ¸ÑĞ»Ğ¾ Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚Ğ¾Ğº Ğ±ĞµÑ€Ñ‘Ñ‚ÑÑ Ğ¸Ğ· SUMMARY_MAX_TRIES.
        """
        deviation = int(self.cfg.get("SUMMARY_DEVIATION_PERCENT", 20))

        n = len(text)
        if n < 500:
            min_len, max_len = 150, 250
        else:
            min_len, max_len = max(150, n // 5), n // 3  # 5:1 Ğ¸ 3:1

        # ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ñ€Ğ°Ğ· Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ±Ğ¾Ğ²Ğ°Ñ‚ÑŒ
        tries = int(self.cfg.get("SUMMARY_MAX_TRIES", 2))
        tries = max(1, tries)  # Ñ…Ğ¾Ñ‚Ñ Ğ±Ñ‹ Ğ¾Ğ´Ğ½Ğ°

        def _generate() -> str:
            prompt = (
                "Ğ¡Ğ´ĞµĞ»Ğ°Ğ¹ ĞºÑ€Ğ°Ñ‚ĞºĞ¾Ğµ Ñ€ĞµĞ·ÑĞ¼Ğµ Ğ¾Ğ±ÑŠÑ‘Ğ¼Ğ¾Ğ¼ Ğ¾Ñ‚ "
                f"{min_len} Ğ´Ğ¾ {max_len} ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ² (Ğ±ĞµĞ· ĞºĞ°Ğ²Ñ‹Ñ‡ĞµĞº, Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‚ĞµĞºÑÑ‚) "
                "Ğ´Ğ»Ñ ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ³Ğ¾ Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ğ¾Ğ³Ğ¾ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ:\n\n"
                f"{text}"
            )
            return (
                self._ollama_call(prompt)
                if self.use_local
                else self._openai_call(prompt)
            ).strip()

        for attempt in range(tries):
            summary = _generate()
            length = len(summary)
            if min_len * (1-(deviation/100)) <= length <= max_len * (1+(deviation/100)):
                # Ğ´Ğ¾Ğ¿ÑƒÑĞº Â±20 % â€” ÑƒÑÑ‚Ñ€Ğ°Ğ¸Ğ²Ğ°ĞµÑ‚
                break
            if attempt == tries - 1:
                # Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ÑÑ Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚ĞºĞ°, Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ¼ ĞºĞ°Ğº ĞµÑÑ‚ÑŒ
                logging.warning(
                    "Summary length %d Ğ²Ğ½Ğµ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ğ° (%dâ€‘%d) Ğ´Ğ°Ğ¶Ğµ Ğ¿Ğ¾ÑĞ»Ğµ %d Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚Ğ¾Ğº",
                    length, min_len, max_len, tries
                )

        return summary

    # â”€â”€â”€ Private helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _ollama_call(self, prompt: str) -> str:
        url = f"{self.cfg['OLLAMA_BASE_URL']}/api/generate"
        payload = {"model": self.cfg["OLLAMA_MODEL"], "prompt": prompt, "stream": False}
        logging.debug("Ollama request: %s", json.dumps(payload)[:200])
        resp = requests.post(url, json=payload, timeout=120)
        resp.raise_for_status()
        summary = resp.json().get("response", "").strip()
        logging.info("Ollama summary len=%d", len(summary))
        return summary

    def _openai_call(self, prompt: str) -> str:
        logging.debug("OpenAI prompt len=%d", len(prompt))
        resp = openai.ChatCompletion.create(
            model=self.cfg["OPENAI_MODEL"],
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
        )
        summary = resp.choices[0].message.content.strip()
        logging.info("OpenAI summary len=%d", len(summary))
        return summary

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Speechâ€‘toâ€‘Text
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class SpeechToText:
    """Handles audio conversion + transcription via Vosk.

    Changing STT backend? Replace *only* this class. Maintain public method
    signatures and the rest of the program will keep working. See the inline
    guide below for hints on swapping models (e.g. Whisper, DeepSpeech â€¦).
    """
    SAMPLE_RATE = 16_000  # ÑƒĞ´Ğ¾Ğ±Ğ½Ğ°Ñ ĞºĞ¾Ğ½ÑÑ‚Ğ°Ğ½Ñ‚Ğ°

    def __init__(self, model_path: str):
        if not Path(model_path).exists():
            raise FileNotFoundError(f"Vosk model not found: {model_path}")
        self.model = Model(model_path)
        logging.info("Loaded Vosk model from %s", model_path)

    # ---------------------------------------------------------------------
    #  PUBLIC API
    # ---------------------------------------------------------------------
    def transcribe_ogg_bytes(self, ogg_bytes: bytes) -> str:
        """OGG âœ WAV âœ TEXT (returns transcription)."""
        with tempfile.NamedTemporaryFile(suffix=".ogg", delete=False) as ogg:
            ogg.write(ogg_bytes)
            ogg_path = Path(ogg.name)
        wav_path = ogg_path.with_suffix(".wav")
        self._ogg_to_wav(ogg_path, wav_path)
        text = self._wav_to_text(wav_path)
        # cleanup temp files
        ogg_path.unlink(missing_ok=True)
        wav_path.unlink(missing_ok=True)
        return text

    # ---------------------------------------------------------------------
    #  INTERNAL HELPERS
    # ---------------------------------------------------------------------
    def _ogg_to_wav(self, ogg_path: Path, wav_path: Path) -> None:
        """
            ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ Ogg/Opus â†’ WAV 16 kHz mono PCM 16-bit
            Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ soundfile (libsndfile) Ğ¸ resampy.
            Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ libsndfile Ğ±Ñ‹Ğ»Ğ° ÑĞºĞ¾Ğ¼Ğ¿Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ° Ñ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¾Ğ¹ Ogg/Opus.
            """
        # 1. Ğ§Ğ¸Ñ‚Ğ°ĞµĞ¼ Ğ°ÑƒĞ´Ğ¸Ğ¾ (Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ ÑÑ‚ĞµÑ€ĞµĞ¾)
        data, sr = sf.read(str(ogg_path))  # data: np.ndarray, sr: Ğ¸ÑÑ…Ğ¾Ğ´Ğ½Ğ°Ñ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ°

        # 2. ĞŸÑ€Ğ¸Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ğº Ğ¼Ğ¾Ğ½Ğ¾, ÑƒÑÑ€ĞµĞ´Ğ½ÑÑ ĞºĞ°Ğ½Ğ°Ğ»Ñ‹
        if data.ndim > 1:
            data = data.mean(axis=1)

        # 3. Ğ ĞµÑĞµĞ¼Ğ¿Ğ»Ğ¸Ñ€ÑƒĞµĞ¼, ĞµÑĞ»Ğ¸ Ğ¸ÑÑ…Ğ¾Ğ´Ğ½Ğ°Ñ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ° != 16 kHz
        if sr != self.SAMPLE_RATE:
            data = resampy.resample(data, sr, self.SAMPLE_RATE)

        # 4. Ğ—Ğ°Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµĞ¼ WAV Ñ PCM 16-bit
        sf.write(str(wav_path), data, self.SAMPLE_RATE, subtype='PCM_16')

    def _wav_to_text(self, wav_path: Path) -> str:
        """Ğ§Ğ¸Ñ‚Ğ°ĞµÑ‚ WAV Ğ¸ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚ Vosk."""
        rec = KaldiRecognizer(self.model, self.SAMPLE_RATE)
        with open(wav_path, "rb") as wf:
            while chunk := wf.read(4000):
                rec.AcceptWaveform(chunk)
        result = json.loads(rec.FinalResult())
        return result.get("text", "").strip()

    # ---------------------------------------------------------------------
    #  HOW TO SWITCH TO ANOTHER STT BACKEND (eg. Whisper)  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ---------------------------------------------------------------------
    # 1. Install the new library (pip installâ€‘U whisperâ€‘cpp â€¦).
    # 2. Delete/replace code inside _wav_to_text() with call into that lib.
    # 3. Make sure transcribe_ogg_bytes() still returns *plain string*.
    # 4. Keep signatures unchanged â‡’ rest of the program stays happy.

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Telegram Bot Wrapper
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class TelegramBot:
    """Encapsulates all Telegramâ€‘specific logic. Runs the event loop."""

    def __init__(
        self,
        token: str,
        db: Database,
        stt: SpeechToText,
        llm: LLMHandler,
    ):
        self.db = db
        self.stt = stt
        self.llm = llm
        self.app = ApplicationBuilder().token(token).build()
        # Register handler for *voice* messages only.
        self.app.add_handler(
            MessageHandler(filters.VOICE & ~filters.COMMAND, self.on_voice)
        )
        self.app.add_handler(CommandHandler("sum", self.on_summary))
        logging.info("Telegram bot initialized â€“ waiting for voice messagesâ€¦")

    # ---------------------------------------------------------------------
    async def on_voice(self, update: Update, ctx: ContextTypes.DEFAULT_TYPE):
        assert isinstance(update.effective_message.voice, Voice)
        voice: Voice = update.effective_message.voice
        sent_at = Utils.now_utc()
        user = update.effective_user
        file_id = voice.file_id
        logging.info(
            "Voice received: file_id=%s | from=%s", file_id, user.username or user.id
        )
        tg_file = await ctx.bot.get_file(file_id)
        ogg_bytes = await tg_file.download_as_bytearray()

        # 1ï¸âƒ£ Transcribe
        text = self.stt.transcribe_ogg_bytes(ogg_bytes)
        logging.info("Transcribed %d chars", len(text))
        logging.info(f"Text: {text}")

        # 2ï¸âƒ£ Summarize
        summary = self.llm.summarize(text)

        # 3ï¸âƒ£ Persist
        self.db.save_message(
            telegram_file_id=file_id,
            text=text,
            summary=summary,
            sent_at=sent_at,
            user_id=user.id,
            username=user.username,
        )

        # 4ï¸âƒ£ Respond with summary
        await update.message.reply_text(
            f"#{file_id} \nğŸ“Œ Ğ ĞµĞ·ÑĞ¼Ğµ: {summary}", parse_mode=constants.ParseMode.HTML,
            reply_to_message_id=update.effective_message.message_id
        )

    async def on_summary(self, update: Update, ctx: ContextTypes.DEFAULT_TYPE):
        text = update.effective_message.text.strip()
        parts = text.split(maxsplit=1)

        # Ğ Ğ°Ğ·Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ´Ğ°Ñ‚Ñƒ Ğ¸Ğ· Ğ°Ñ€Ğ³ÑƒĞ¼ĞµĞ½Ñ‚Ğ° Ğ¸Ğ»Ğ¸ Ğ±ĞµÑ€Ñ‘Ğ¼ ÑĞµĞ³Ğ¾Ğ´Ğ½ÑÑ‰ĞµĞµ Ñ‡Ğ¸ÑĞ»Ğ¾ Ğ² Warsaw
        if len(parts) > 1:
            date_str = parts[1]
            try:
                datetime.datetime.strptime(date_str, "%Y-%m-%d")
            except ValueError:
                await update.message.reply_text("â—ï¸ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ´Ğ°Ñ‚Ñ‹. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ YYYY-MM-DD")
                return
        else:
            # Europe/Warsaw = UTC+2
            tz = datetime.timezone(datetime.timedelta(hours=2))
            date_str = datetime.datetime.now(tz).date().isoformat()

        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¸Ğ· Ğ‘Ğ”
        summaries = self.db.fetch_summaries_by_date(date_str)
        if not summaries:
            await update.message.reply_text(f"â„¹ï¸ ĞĞµÑ‚ Ñ€ĞµĞ·ÑĞ¼Ğµ Ğ·Ğ° {date_str}.")
            return

        # Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¸ ÑˆĞ»Ñ‘Ğ¼
        lines = []
        for sent_at, telegram_file_id, summary in summaries:
            lines.append(f"{sent_at} â€” #{telegram_file_id}: {summary}")

        # Ğ•ÑĞ»Ğ¸ Ğ¾Ñ‡ĞµĞ½ÑŒ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ ÑÑ‚Ñ€Ğ¾Ğº, Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ñ€Ğ°Ğ·Ğ±Ğ¸Ñ‚ÑŒ Ğ½Ğ° Ñ‡Ğ°ÑÑ‚Ğ¸
        await update.message.reply_text("\n".join(lines))

    # ---------------------------------------------------------------------
    def run(self):
        """Kickâ€‘off polling loop (Ctrlâ€‘C to exit)."""
        self.app.run_polling()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Entryâ€‘Point
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    load_dotenv(dotenv_path='.env')

    # Configure logging *first* so other classes can log.
    Utils.configure_logging(os.getenv("LOG_FILE", "bot.log"))

    # Instantiate subâ€‘systems using envâ€‘config.
    db = Database(os.getenv("DB_PATH", "bot.db"))

    stt = SpeechToText(model_path=os.getenv("VOSK_MODEL_PATH", "models/voskâ€‘smallâ€‘ruâ€‘0.22"))

    llm = LLMHandler(
        use_local=Utils.as_bool(os.getenv("USE_LOCAL_LLM", "True")),
        cfg=os.environ,  # pass entire dict; handler reads what it needs
    )

    bot = TelegramBot(
        token=os.environ["TG_BOT_TOKEN"],
        db=db,
        stt=stt,
        llm=llm,
    )

    bot.run()


if __name__ == "__main__":
    try:
        main()
    except Exception as exc:
        logging.exception("Fatal error: %s", exc)
        raise
